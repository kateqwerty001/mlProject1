{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_all = pd.read_csv('../data/data.csv')\n",
    "\n",
    "train, test = train_test_split(data_all, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = train.drop(['CREDIT_SCORE','DEFAULT'], axis=1)\n",
    "y_train = train['DEFAULT']\n",
    "\n",
    "X_test = test.drop(['CREDIT_SCORE','DEFAULT'], axis=1)\n",
    "y_test = test['DEFAULT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class BaseColumnsSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, subset):\n",
    "        self.subset = subset\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, self.subset]\n",
    "    \n",
    "baseColumns = ['INCOME', 'SAVINGS', 'DEBT', 'T_CLOTHING_12', 'T_CLOTHING_6', \n",
    "       'T_EDUCATION_12', 'T_EDUCATION_6', 'T_ENTERTAINMENT_12',\n",
    "       'T_ENTERTAINMENT_6', 'T_FINES_12',\n",
    "       'T_FINES_6', 'T_GAMBLING_12', 'T_GAMBLING_6', \n",
    "       'T_GROCERIES_12', 'T_GROCERIES_6', 'T_HEALTH_12', 'T_HEALTH_6',\n",
    "       'T_HOUSING_12', 'T_HOUSING_6', 'T_TAX_12', 'T_TAX_6', 'T_TRAVEL_12',\n",
    "       'T_TRAVEL_6', 'R_TRAVEL', 'T_UTILITIES_12', 'T_UTILITIES_6', \n",
    "       'T_EXPENDITURE_12', 'T_EXPENDITURE_6', \n",
    "       'CAT_GAMBLING', 'CAT_CREDIT_CARD', 'CAT_MORTGAGE',\n",
    "       'CAT_SAVINGS_ACCOUNT', 'CAT_DEPENDENTS']\n",
    "\n",
    "groups = ['CLOTHING', 'EDUCATION', 'ENTERTAINMENT', 'FINES', 'GAMBLING', 'GROCERIES', 'HEALTH', 'HOUSING', 'TAX', 'TRAVEL', 'UTILITIES']\n",
    "no_sense_in_division =['T_EDUCATION_12', 'T_FINES_12', 'T_GAMBLING_12', 'T_HOUSING_12', 'T_TAX_12', 'T_TRAVEL_12']\n",
    "division_groups = ['CLOTHING',  'ENTERTAINMENT',  'GROCERIES', 'HEALTH',  'UTILITIES']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#być może zrobić fines_6 i fines_12 jako kategoryczne???? i gambling_6 i gambling_12 też\n",
    "class OutliersReplacer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for column in X.columns:\n",
    "            if column == 'SAVINGS':\n",
    "                X.loc[X[column] > 2500000, column] = 2500000\n",
    "            elif column == 'DEBT':\n",
    "                X.loc[X[column] > 4000000, column] = 4000000\n",
    "            elif column == 'T_CLOTHING_12':\n",
    "                X.loc[X[column] > 32000, column] = 32000\n",
    "            elif column == 'T_CLOTHING_6':\n",
    "                X.loc[X[column] > 25000, column] = 25000\n",
    "            elif column == 'T_HEALTH_12':\n",
    "                X.loc[X[column] > 25000, column] = 25000\n",
    "            elif column == 'T_HEALTH_6':\n",
    "                X.loc[X[column] > 18000, column] = 18000\n",
    "            elif column == 'T_TRAVEL_12':\n",
    "                X.loc[X[column] > 150000, column] = 150000\n",
    "            elif column == 'T_TRAVEL_6':\n",
    "                X.loc[X[column] > 110000, column] = 110000\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatioColumnsAdder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for idx, row in X.iterrows():\n",
    "            #DEBT/INCOME\n",
    "            if row['INCOME'] == 0:\n",
    "                X.at[idx, 'R_DEBT_INCOME'] = None\n",
    "            else:\n",
    "                X.at[idx, 'R_DEBT_INCOME'] = row['DEBT'] / row['INCOME']\n",
    "            #SAVINGS/INCOME\n",
    "            if row['INCOME'] == 0:\n",
    "                X.at[idx, 'R_SAVINGS_INCOME'] = None\n",
    "            else:\n",
    "                X.at[idx, 'R_SAVINGS_INCOME'] = row['SAVINGS'] / row['INCOME']\n",
    "            #DEBT/SAVINGS\n",
    "            if row['SAVINGS'] == 0:\n",
    "                X.at[idx, 'R_DEBT_SAVINGS'] = None\n",
    "            else:\n",
    "                X.at[idx, 'R_DEBT_SAVINGS'] = row['DEBT'] / row['SAVINGS']\n",
    "            for group in division_groups:\n",
    "                if row['T_' + group + '_12'] == 0:\n",
    "                    X.at[idx, 'R_' + group] = None\n",
    "                else:\n",
    "                    X.at[idx, 'R_' + group] = row['T_' + group + '_6'] / row['T_' + group + '_12']\n",
    "            for group in groups:\n",
    "                if row['INCOME'] == 0:\n",
    "                    X.at[idx, 'R_'+group+'_INCOME'] = None\n",
    "                else:\n",
    "                    X.at[idx, 'R_'+group+'_INCOME'] = row['T_'+group+'_6'] / row['INCOME']\n",
    "                    \n",
    "                if row['SAVINGS'] == 0:\n",
    "                    X.at[idx, 'R_'+group+'_SAVINGS'] = None\n",
    "                else:\n",
    "                    X.at[idx, 'R_'+group+'_SAVINGS'] = row['T_'+group+'_6'] / row['SAVINGS']\n",
    "\n",
    "                if row['DEBT'] == 0:\n",
    "                    X.at[idx, 'R_'+group+'_DEBT'] = None\n",
    "                else:\n",
    "                    X.at[idx, 'R_'+group+'_DEBT'] = row['T_'+group+'_6'] / row['DEBT']\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        potentialColumnsToDrop = ['T_EDUCATION_12', 'T_FINES_12', 'T_GAMBLING_12', 'T_HOUSING_12', 'T_TAX_12', 'T_TRAVEL_12', 'T_EDUCATION_6','T_ENTERTAINMENT_6','T_GAMBLING_6','T_GROCERIES_6','T_HOUSING_6','T_EXPENDITURE_12', 'T_EXPENDITURE_6','R_GROCERIES_DEBT', 'INCOME', 'T_UTILITIES_6', 'R_EDUCATION_DEBT', 'T_UTILITIES_12', 'R_CLOTHING_DEBT',\n",
    "        'CAT_DEPENDENTS', 'R_ENTERTAINMENT_SAVINGS', 'R_FINES_INCOME',\n",
    "        'R_FINES_SAVINGS', 'R_FINES_DEBT', 'R_GROCERIES_SAVINGS',\n",
    "        'CAT_SAVINGS_ACCOUNT', 'R_HOUSING_INCOME', 'R_TAX_INCOME',\n",
    "        'R_TAX_SAVINGS', 'R_TRAVEL_DEBT', 'R_UTILITIES_DEBT', 'CAT_GAMBLING',\n",
    "        'CAT_DEBT', 'CAT_MORTGAGE', 'SAVINGS', 'R_UTILITIES_SAVINGS', 'R_EDUCATION', 'R_FINES', 'R_GAMBLING', 'R_HOUSING', 'R_GROCERIES_INCOME', 'T_ENTERTAINMENT_12', 'R_ENTERTAINMENT',\n",
    "       'R_TRAVEL_SAVINGS', 'R_GAMBLING_SAVINGS', 'T_CLOTHING_6']\n",
    "        for column in potentialColumnsToDrop:\n",
    "            if column in X.columns:\n",
    "                X.drop(column, axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "class MissingValuesFiller(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        numerical_columns = X.select_dtypes(include=[np.number]).columns\n",
    "        imputer = KNNImputer(n_neighbors=7)\n",
    "        X[numerical_columns] = imputer.fit_transform(X[numerical_columns])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_smoothing: 1e-09, accuracy: 0.653125, recall: 0.23537795537795536, precision: 0.3486322223503633, f1: 0.27917201912743145\n",
      "var_smoothing: 1e-08, accuracy: 0.6546875, recall: 0.24563436563436564, precision: 0.3551282944386393, f1: 0.2888138079085927\n",
      "var_smoothing: 1e-07, accuracy: 0.653125, recall: 0.24050616050616053, precision: 0.3477633477633477, f1: 0.2828738320867121\n",
      "var_smoothing: 1e-06, accuracy: 0.65, recall: 0.22907758907758907, precision: 0.33887445887445883, f1: 0.272121143914669\n",
      "var_smoothing: 1e-05, accuracy: 0.6609375, recall: 0.22907758907758907, precision: 0.3573268921095008, f1: 0.2783693920550902\n"
     ]
    }
   ],
   "source": [
    "#best parameters :\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#standart scaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "for var_sm in [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]:\n",
    "            pipeline = Pipeline([\n",
    "                ('selector', BaseColumnsSelector(baseColumns)),\n",
    "                ('outliers_replacer', OutliersReplacer()),\n",
    "                ('ratio_columns_adder', RatioColumnsAdder()),\n",
    "                ('missing_values_filler', MissingValuesFiller()),\n",
    "                ('drop_columns', DropColumns()),\n",
    "                ('classifier', GaussianNB(var_smoothing=var_sm))\n",
    "            ])\n",
    "            kfold = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "            score_acc = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "            score_recall = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='recall')\n",
    "            score_precision = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='precision')\n",
    "            score_f1 = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='f1')\n",
    "            print(f\"var_smoothing: {var_sm}, accuracy: {score_acc.mean()}, recall: {score_recall.mean()}, precision: {score_precision.mean()}, f1: {score_f1.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.65625, recall: 0.2427385492904069, precision: 0.3537112887112887, f1: 0.286510848853648\n"
     ]
    }
   ],
   "source": [
    "#best parameters :\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#standart scaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selector', BaseColumnsSelector(baseColumns)),\n",
    "    ('outliers_replacer', OutliersReplacer()),\n",
    "    ('ratio_columns_adder', RatioColumnsAdder()),\n",
    "    ('missing_values_filler', MissingValuesFiller()),\n",
    "    ('drop_columns', DropColumns()),\n",
    "    ('classifier', GaussianNB(var_smoothing=1e-5))\n",
    "])\n",
    "\n",
    "#validation \n",
    "kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "score_acc = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "score_recall = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='recall')\n",
    "score_precision = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='precision')\n",
    "score_f1 = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='f1')\n",
    "print(f\"accuracy: {score_acc.mean()}, recall: {score_recall.mean()}, precision: {score_precision.mean()}, f1: {score_f1.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6125\n",
      "[[95 19]\n",
      " [43  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75       114\n",
      "           1       0.14      0.07      0.09        46\n",
      "\n",
      "    accuracy                           0.61       160\n",
      "   macro avg       0.41      0.45      0.42       160\n",
      "weighted avg       0.53      0.61      0.56       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6.86x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
