{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_all = pd.read_csv('../data/data.csv')\n",
    "\n",
    "train, test = train_test_split(data_all, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_imbalanced = train.drop(['CREDIT_SCORE','DEFAULT'], axis=1)\n",
    "y_train_imbalanced = train['DEFAULT']\n",
    "\n",
    "X_test = test.drop(['CREDIT_SCORE','DEFAULT'], axis=1)\n",
    "y_test = test['DEFAULT']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train, y_train = ros.fit_resample(X_train_imbalanced, y_train_imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class OutliersReplacer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for column in X.columns:\n",
    "            if column == 'SAVINGS':\n",
    "                X.loc[X[column] > 2500000, column] = 2500000\n",
    "            elif column == 'DEBT':\n",
    "                X.loc[X[column] > 4000000, column] = 4000000\n",
    "            elif column == 'T_CLOTHING_12':\n",
    "                X.loc[X[column] > 32000, column] = 32000\n",
    "            elif column == 'T_CLOTHING_6':\n",
    "                X.loc[X[column] > 25000, column] = 25000\n",
    "            elif column == 'T_HEALTH_12':\n",
    "                X.loc[X[column] > 25000, column] = 25000\n",
    "            elif column == 'T_HEALTH_6':\n",
    "                X.loc[X[column] > 18000, column] = 18000\n",
    "            elif column == 'T_TRAVEL_12':\n",
    "                X.loc[X[column] > 150000, column] = 150000\n",
    "            elif column == 'T_TRAVEL_6':\n",
    "                X.loc[X[column] > 110000, column] = 110000\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        potentialColumnsToDrop = ['T_EDUCATION_12', 'T_FINES_12', 'T_GAMBLING_12', 'T_HOUSING_12', 'T_TAX_12', 'T_TRAVEL_12', 'T_EDUCATION_6','T_ENTERTAINMENT_6','T_GAMBLING_6','T_GROCERIES_6','T_HOUSING_6','T_EXPENDITURE_12', 'T_EXPENDITURE_6','R_GROCERIES_DEBT', 'INCOME', 'T_UTILITIES_6', 'R_EDUCATION_DEBT', 'T_UTILITIES_12', 'R_CLOTHING_DEBT',\n",
    "        'CAT_DEPENDENTS', 'R_ENTERTAINMENT_SAVINGS', 'R_FINES_INCOME',\n",
    "        'R_FINES_SAVINGS', 'R_FINES_DEBT', 'R_GROCERIES_SAVINGS',\n",
    "        'CAT_SAVINGS_ACCOUNT', 'R_HOUSING_INCOME', 'R_TAX_INCOME',\n",
    "        'R_TAX_SAVINGS', 'R_TRAVEL_DEBT', 'R_UTILITIES_DEBT', 'CAT_GAMBLING',\n",
    "        'CAT_DEBT', 'CAT_MORTGAGE', 'SAVINGS', 'R_UTILITIES_SAVINGS', 'R_EDUCATION', 'R_FINES', 'R_GAMBLING', 'R_HOUSING', 'R_GROCERIES_INCOME', 'T_ENTERTAINMENT_12', 'R_ENTERTAINMENT',\n",
    "       'R_TRAVEL_SAVINGS', 'R_GAMBLING_SAVINGS', 'T_CLOTHING_6', 'CUST_ID']\n",
    "        for column in potentialColumnsToDrop:\n",
    "            if column in X.columns:\n",
    "                X.drop(column, axis=1, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 13, max_depth: 2, learning_rate: 0.1, accuracy: 0.6623148590539895, recall: 0.6673893768944317, precision: 0.6605438048359396, f1: 0.6598495442740866\n",
      "n_estimators: 13, max_depth: 2, learning_rate: 0.2, accuracy: 0.6830745341614908, recall: 0.6740928628405071, precision: 0.6803635308656124, f1: 0.676500026888873\n",
      "n_estimators: 13, max_depth: 2, learning_rate: 0.3, accuracy: 0.7092928810320115, recall: 0.7424532271149789, precision: 0.6949834546154713, f1: 0.7119856380886086\n",
      "n_estimators: 13, max_depth: 3, learning_rate: 0.1, accuracy: 0.7201385570950788, recall: 0.7208109563543718, precision: 0.7219235187867337, f1: 0.7196555429252351\n",
      "n_estimators: 13, max_depth: 3, learning_rate: 0.2, accuracy: 0.7321070234113712, recall: 0.7733311970540355, precision: 0.7169265217230618, f1: 0.7429839201710143\n",
      "n_estimators: 13, max_depth: 3, learning_rate: 0.3, accuracy: 0.7549569995222168, recall: 0.7768623418894985, precision: 0.734905190509343, f1: 0.7540701083038609\n",
      "n_estimators: 14, max_depth: 2, learning_rate: 0.1, accuracy: 0.6645604395604396, recall: 0.660908378915605, precision: 0.6665693450734482, f1: 0.661646187465581\n",
      "n_estimators: 14, max_depth: 2, learning_rate: 0.2, accuracy: 0.6928690874343049, recall: 0.6968080489235543, precision: 0.6910271702792092, f1: 0.6925202576119791\n",
      "n_estimators: 14, max_depth: 2, learning_rate: 0.3, accuracy: 0.7092689918776875, recall: 0.7312107150678638, precision: 0.6991104357701702, f1: 0.711944763176769\n",
      "n_estimators: 14, max_depth: 3, learning_rate: 0.1, accuracy: 0.7212613473483038, recall: 0.7256320980364157, precision: 0.7178823580714336, f1: 0.7213406010070788\n",
      "n_estimators: 14, max_depth: 3, learning_rate: 0.2, accuracy: 0.7419254658385093, recall: 0.7787467102854301, precision: 0.7221704596983475, f1: 0.747697548074722\n",
      "n_estimators: 14, max_depth: 3, learning_rate: 0.3, accuracy: 0.7680243669374104, recall: 0.8028003531704501, precision: 0.7489969588783267, f1: 0.7709564640675901\n",
      "n_estimators: 15, max_depth: 2, learning_rate: 0.1, accuracy: 0.6612756808408984, recall: 0.6612600711543319, precision: 0.6651570061046714, f1: 0.6590463948836491\n",
      "n_estimators: 15, max_depth: 2, learning_rate: 0.2, accuracy: 0.7015527950310559, recall: 0.7140518547319216, precision: 0.6955271882732551, f1: 0.6982842282969858\n",
      "n_estimators: 15, max_depth: 2, learning_rate: 0.3, accuracy: 0.7114429049211658, recall: 0.7351701082006574, precision: 0.69955939624566, f1: 0.7122970832595985\n",
      "n_estimators: 15, max_depth: 3, learning_rate: 0.1, accuracy: 0.7092689918776875, recall: 0.7154129565422783, precision: 0.7086287719033391, f1: 0.7078570136093199\n",
      "n_estimators: 15, max_depth: 3, learning_rate: 0.2, accuracy: 0.7462852365026278, recall: 0.7939353015825755, precision: 0.7199256368386998, f1: 0.7541866197280822\n",
      "n_estimators: 15, max_depth: 3, learning_rate: 0.3, accuracy: 0.7669493549928331, recall: 0.8050717692489252, precision: 0.7435129721627647, f1: 0.7717784465503581\n",
      "n_estimators: 16, max_depth: 2, learning_rate: 0.1, accuracy: 0.6688843764930722, recall: 0.6767346606478102, precision: 0.6675309678884987, f1: 0.6637073135643127\n",
      "n_estimators: 16, max_depth: 2, learning_rate: 0.2, accuracy: 0.6928690874343049, recall: 0.7145125011214144, precision: 0.6923010302927051, f1: 0.6960761651116132\n",
      "n_estimators: 16, max_depth: 2, learning_rate: 0.3, accuracy: 0.7136526516961299, recall: 0.7318787676600768, precision: 0.7009157212697995, f1: 0.7148424313624778\n",
      "n_estimators: 16, max_depth: 3, learning_rate: 0.1, accuracy: 0.7223244147157191, recall: 0.728930821034387, precision: 0.7181861132041444, f1: 0.7211828668813145\n",
      "n_estimators: 16, max_depth: 3, learning_rate: 0.2, accuracy: 0.7538700430004777, recall: 0.7934877384805007, precision: 0.7402173812491826, f1: 0.7620935895408991\n",
      "n_estimators: 16, max_depth: 3, learning_rate: 0.3, accuracy: 0.7767439082656473, recall: 0.8121961412109915, precision: 0.7517142526256498, f1: 0.7789350716762127\n",
      "n_estimators: 17, max_depth: 2, learning_rate: 0.1, accuracy: 0.6721333014811277, recall: 0.6736855123698985, precision: 0.6702384109163637, f1: 0.6676525718659712\n",
      "n_estimators: 17, max_depth: 2, learning_rate: 0.2, accuracy: 0.7048256091734353, recall: 0.715094922970102, precision: 0.6950989875446567, f1: 0.7073176241098071\n",
      "n_estimators: 17, max_depth: 2, learning_rate: 0.3, accuracy: 0.7114548494983277, recall: 0.7346699337719116, precision: 0.7053543770621388, f1: 0.7125979407769449\n",
      "n_estimators: 17, max_depth: 3, learning_rate: 0.1, accuracy: 0.7102962255136168, recall: 0.7192417458717192, precision: 0.7058847741013933, f1: 0.7091919776866507\n",
      "n_estimators: 17, max_depth: 3, learning_rate: 0.2, accuracy: 0.7593406593406593, recall: 0.7894814623043083, precision: 0.7420767423080077, f1: 0.7653287466919395\n",
      "n_estimators: 17, max_depth: 3, learning_rate: 0.3, accuracy: 0.7669612995699951, recall: 0.8102757551703963, precision: 0.746348308423664, f1: 0.7743554053462528\n",
      "n_estimators: 18, max_depth: 2, learning_rate: 0.1, accuracy: 0.6699832775919733, recall: 0.6744187574259836, precision: 0.6721872035412274, f1: 0.6696201374703976\n",
      "n_estimators: 18, max_depth: 2, learning_rate: 0.2, accuracy: 0.6993788819875777, recall: 0.7317969859090987, precision: 0.6976345397600919, f1: 0.7036149395364139\n",
      "n_estimators: 18, max_depth: 2, learning_rate: 0.3, accuracy: 0.7124820831342571, recall: 0.7390293442027506, precision: 0.708400458787551, f1: 0.7161048174054789\n",
      "n_estimators: 18, max_depth: 3, learning_rate: 0.1, accuracy: 0.7135690396559962, recall: 0.7225537710327169, precision: 0.7124928570304296, f1: 0.7131644757518429\n",
      "n_estimators: 18, max_depth: 3, learning_rate: 0.2, accuracy: 0.757190635451505, recall: 0.8054086848888657, precision: 0.7337719933121256, f1: 0.7648724553473112\n",
      "n_estimators: 18, max_depth: 3, learning_rate: 0.3, accuracy: 0.7712971810797897, recall: 0.813847482106785, precision: 0.7486276900608382, f1: 0.7781515560260438\n",
      "n_estimators: 19, max_depth: 2, learning_rate: 0.1, accuracy: 0.6732202580028668, recall: 0.6910366584951041, precision: 0.6684032882638075, f1: 0.6750934368257692\n",
      "n_estimators: 19, max_depth: 2, learning_rate: 0.2, accuracy: 0.7069875776397516, recall: 0.7302722665121072, precision: 0.6989164829958885, f1: 0.7102888110945442\n",
      "n_estimators: 19, max_depth: 2, learning_rate: 0.3, accuracy: 0.7265886287625418, recall: 0.7543467356667586, precision: 0.7128072317373321, f1: 0.7339770663663565\n",
      "n_estimators: 19, max_depth: 3, learning_rate: 0.1, accuracy: 0.7146918299092212, recall: 0.7208006932833986, precision: 0.7114145184428323, f1: 0.7137010717045642\n",
      "n_estimators: 19, max_depth: 3, learning_rate: 0.2, accuracy: 0.7593645484949832, recall: 0.8103649243334503, precision: 0.7373743245860496, f1: 0.7706737182002636\n",
      "n_estimators: 19, max_depth: 3, learning_rate: 0.3, accuracy: 0.7854992833253702, recall: 0.8379707403341866, precision: 0.7579458764573979, f1: 0.7950522386129304\n",
      "n_estimators: 20, max_depth: 2, learning_rate: 0.1, accuracy: 0.6786789297658864, recall: 0.687793948060481, precision: 0.678070065854424, f1: 0.6783116738059103\n",
      "n_estimators: 20, max_depth: 2, learning_rate: 0.2, accuracy: 0.7037147634973723, recall: 0.7258449777729716, precision: 0.6993186942010698, f1: 0.7149610266972899\n",
      "n_estimators: 20, max_depth: 2, learning_rate: 0.3, accuracy: 0.7396559961777353, recall: 0.763992203642962, precision: 0.7240283967593705, f1: 0.7442350956986041\n",
      "n_estimators: 20, max_depth: 3, learning_rate: 0.1, accuracy: 0.7244983277591974, recall: 0.7376546318359336, precision: 0.7192196495515313, f1: 0.7245704369058974\n",
      "n_estimators: 20, max_depth: 3, learning_rate: 0.2, accuracy: 0.76589823220258, recall: 0.8089421763395489, precision: 0.7411910325479111, f1: 0.7736806978554782\n",
      "n_estimators: 20, max_depth: 3, learning_rate: 0.3, accuracy: 0.7789417104634495, recall: 0.8211726783293576, precision: 0.7596090194006961, f1: 0.7899821448801603\n",
      "n_estimators: 21, max_depth: 2, learning_rate: 0.1, accuracy: 0.6710463449593884, recall: 0.6883221150442785, precision: 0.6667765609721876, f1: 0.6719420735959504\n",
      "n_estimators: 21, max_depth: 2, learning_rate: 0.2, accuracy: 0.7015647396082179, recall: 0.7203326431766273, precision: 0.6927859496134006, f1: 0.7045027827809883\n",
      "n_estimators: 21, max_depth: 2, learning_rate: 0.3, accuracy: 0.73640707118968, recall: 0.759630102329641, precision: 0.7233425728250695, f1: 0.7405129986045454\n",
      "n_estimators: 21, max_depth: 3, learning_rate: 0.1, accuracy: 0.7321428571428571, recall: 0.7455943221692409, precision: 0.7224250348274086, f1: 0.7324558290070823\n",
      "n_estimators: 21, max_depth: 3, learning_rate: 0.2, accuracy: 0.7604276158623985, recall: 0.8132661904980578, precision: 0.7407319410897578, f1: 0.7686584427951149\n",
      "n_estimators: 21, max_depth: 3, learning_rate: 0.3, accuracy: 0.7843884376493071, recall: 0.8273501412173468, precision: 0.7601071391218307, f1: 0.79249135282104\n",
      "n_estimators: 22, max_depth: 2, learning_rate: 0.1, accuracy: 0.6798136645962733, recall: 0.6837967560736308, precision: 0.677798178493693, f1: 0.6756734106778628\n",
      "n_estimators: 22, max_depth: 2, learning_rate: 0.2, accuracy: 0.70376254180602, recall: 0.7280069874069859, precision: 0.6984508230418227, f1: 0.7089135814751849\n",
      "n_estimators: 22, max_depth: 2, learning_rate: 0.3, accuracy: 0.7451743908265647, recall: 0.7745585037196038, precision: 0.7351246175616606, f1: 0.7505149775796589\n",
      "n_estimators: 22, max_depth: 3, learning_rate: 0.1, accuracy: 0.7288580984233158, recall: 0.7433223513208375, precision: 0.7176560689275259, f1: 0.7284249035410852\n",
      "n_estimators: 22, max_depth: 3, learning_rate: 0.2, accuracy: 0.7669732441471572, recall: 0.8129916046215, precision: 0.7470204897598373, f1: 0.7792037220025974\n",
      "n_estimators: 22, max_depth: 3, learning_rate: 0.3, accuracy: 0.7974438604873387, recall: 0.8582295274460723, precision: 0.766765558086287, f1: 0.8081850852063888\n",
      "n_estimators: 23, max_depth: 2, learning_rate: 0.1, accuracy: 0.6776278069756331, recall: 0.6798567667274431, precision: 0.6757824749059914, f1: 0.6739766239889515\n",
      "n_estimators: 23, max_depth: 2, learning_rate: 0.2, accuracy: 0.7081103678929767, recall: 0.7237029581029566, precision: 0.7000469082813442, f1: 0.7060388002141319\n",
      "n_estimators: 23, max_depth: 2, learning_rate: 0.3, accuracy: 0.7495222169135212, recall: 0.7747753058876256, precision: 0.7393818764556912, f1: 0.7528361486931814\n",
      "n_estimators: 23, max_depth: 3, learning_rate: 0.1, accuracy: 0.7332059245102723, recall: 0.7622589668835926, precision: 0.7183121964878794, f1: 0.7355536064515286\n",
      "n_estimators: 23, max_depth: 3, learning_rate: 0.2, accuracy: 0.7647873865265169, recall: 0.8219995411294365, precision: 0.7406566983711836, f1: 0.7752372717991445\n",
      "n_estimators: 23, max_depth: 3, learning_rate: 0.3, accuracy: 0.7963449593884376, recall: 0.8516522611094992, precision: 0.7663966154438696, f1: 0.8069651286205299\n"
     ]
    }
   ],
   "source": [
    "#best parameters :\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "for n_est in range(13, 24, 1):\n",
    "    for depth in range(2, 4, 1):\n",
    "        for lr in [0.1, 0.2, 0.3]:\n",
    "            pipeline = Pipeline([\n",
    "                ('outliers_replacer', OutliersReplacer()),\n",
    "                ('drop_columns', DropColumns()),\n",
    "                ('classifier', GradientBoostingClassifier(n_estimators=n_est, max_depth=depth, learning_rate=lr))\n",
    "            ])\n",
    "            kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "            score_acc = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "            score_recall = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='recall')\n",
    "            score_precision = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='precision')\n",
    "            score_f1 = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='f1')\n",
    "            print(f\"n_estimators: {n_est}, max_depth: {depth}, learning_rate: {lr}, accuracy: {score_acc.mean()}, recall: {score_recall.mean()}, precision: {score_precision.mean()}, f1: {score_f1.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 24, max_depth: 2, learning_rate: 0.1, accuracy: 0.6787386526516961, recall: 0.682356766727443, precision: 0.6781522198089944, f1: 0.6755349940903919\n",
      "n_estimators: 24, max_depth: 2, learning_rate: 0.2, accuracy: 0.711371237458194, recall: 0.7456497894670813, precision: 0.7081265810336485, f1: 0.7158172481785078\n",
      "n_estimators: 24, max_depth: 2, learning_rate: 0.3, accuracy: 0.758265647396082, recall: 0.7734494811632129, precision: 0.7426642198381328, f1: 0.7630697068364846\n",
      "n_estimators: 24, max_depth: 2, learning_rate: 0.4, accuracy: 0.74848303870043, recall: 0.7757595178350785, precision: 0.7367386408633907, f1: 0.7523524281824202\n",
      "n_estimators: 24, max_depth: 3, learning_rate: 0.1, accuracy: 0.7505852842809364, recall: 0.7851806366212355, precision: 0.7312547500180012, f1: 0.7506584639934842\n",
      "n_estimators: 24, max_depth: 3, learning_rate: 0.2, accuracy: 0.773471094123268, recall: 0.8197013869603135, precision: 0.7424256418267913, f1: 0.7781706950326708\n",
      "n_estimators: 24, max_depth: 3, learning_rate: 0.3, accuracy: 0.799629718107979, recall: 0.8559828202525566, precision: 0.7697786672986477, f1: 0.804855932304814\n",
      "n_estimators: 24, max_depth: 3, learning_rate: 0.4, accuracy: 0.8050645007166747, recall: 0.8496930764284183, precision: 0.7724347249639956, f1: 0.8077254772873337\n",
      "n_estimators: 25, max_depth: 2, learning_rate: 0.1, accuracy: 0.676564739608218, recall: 0.6793988912695675, precision: 0.6764292046085332, f1: 0.6728581626130324\n",
      "n_estimators: 25, max_depth: 2, learning_rate: 0.2, accuracy: 0.7168299092212136, recall: 0.7574017213143929, precision: 0.7133855707479464, f1: 0.7189789712586884\n",
      "n_estimators: 25, max_depth: 2, learning_rate: 0.3, accuracy: 0.748459149546106, recall: 0.7718112392168837, precision: 0.7416628040327454, f1: 0.752379111104256\n",
      "n_estimators: 25, max_depth: 2, learning_rate: 0.4, accuracy: 0.7560797897754419, recall: 0.7881580547041, precision: 0.7437149030428605, f1: 0.764546023700089\n",
      "n_estimators: 25, max_depth: 3, learning_rate: 0.1, accuracy: 0.7440635451505017, recall: 0.7764336412508316, precision: 0.7298073742166087, f1: 0.7493301825311383\n",
      "n_estimators: 25, max_depth: 3, learning_rate: 0.2, accuracy: 0.7745699952221691, recall: 0.8226082476078673, precision: 0.7453824705382922, f1: 0.7819196062025358\n",
      "n_estimators: 25, max_depth: 3, learning_rate: 0.3, accuracy: 0.7952699474438604, recall: 0.8581191324108653, precision: 0.7674251817572741, f1: 0.8072643627268661\n",
      "n_estimators: 25, max_depth: 3, learning_rate: 0.4, accuracy: 0.808337314859054, recall: 0.8610328252122443, precision: 0.7804071600939932, f1: 0.8104628301527782\n",
      "n_estimators: 26, max_depth: 2, learning_rate: 0.1, accuracy: 0.677639751552795, recall: 0.6818379156598116, precision: 0.6797546838025623, f1: 0.6760134576561847\n",
      "n_estimators: 26, max_depth: 2, learning_rate: 0.2, accuracy: 0.7179168657429527, recall: 0.750577856618256, precision: 0.7076763912552513, f1: 0.7277067252120175\n",
      "n_estimators: 26, max_depth: 2, learning_rate: 0.3, accuracy: 0.764763497372193, recall: 0.7905321083288219, precision: 0.7517762196632235, f1: 0.764938958939924\n",
      "n_estimators: 26, max_depth: 2, learning_rate: 0.4, accuracy: 0.7702102245580507, recall: 0.7900397199022979, precision: 0.7525403951996549, f1: 0.7662098811449655\n",
      "n_estimators: 26, max_depth: 3, learning_rate: 0.1, accuracy: 0.7527830864787386, recall: 0.7844133757443921, precision: 0.7328539751322107, f1: 0.7577246185767545\n",
      "n_estimators: 26, max_depth: 3, learning_rate: 0.2, accuracy: 0.7778547539417104, recall: 0.827048539585285, precision: 0.7479172281948785, f1: 0.7839698426723131\n",
      "n_estimators: 26, max_depth: 3, learning_rate: 0.3, accuracy: 0.8007047300525562, recall: 0.8616997912514825, precision: 0.7700040036894149, f1: 0.8047955768871915\n",
      "n_estimators: 26, max_depth: 3, learning_rate: 0.4, accuracy: 0.8061514572384137, recall: 0.8568051829358216, precision: 0.7761730034202825, f1: 0.8104214875925597\n",
      "n_estimators: 27, max_depth: 2, learning_rate: 0.1, accuracy: 0.6819636884854277, recall: 0.6883877189733326, precision: 0.6827293624096367, f1: 0.681728799770011\n",
      "n_estimators: 27, max_depth: 2, learning_rate: 0.2, accuracy: 0.7244386048733875, recall: 0.7413334314527782, precision: 0.7074005906273795, f1: 0.7204836804507205\n",
      "n_estimators: 27, max_depth: 2, learning_rate: 0.3, accuracy: 0.7603798375537506, recall: 0.7958306624958887, precision: 0.7511522585525805, f1: 0.7686740631596496\n",
      "n_estimators: 27, max_depth: 2, learning_rate: 0.4, accuracy: 0.7691471571906353, recall: 0.8102025006949779, precision: 0.7489149344989765, f1: 0.7745437591569766\n",
      "n_estimators: 27, max_depth: 3, learning_rate: 0.1, accuracy: 0.7538700430004777, recall: 0.7792478022361535, precision: 0.7340584493726543, f1: 0.7587995143516317\n",
      "n_estimators: 27, max_depth: 3, learning_rate: 0.2, accuracy: 0.7767677974199714, recall: 0.8282260024732742, precision: 0.7508927533677529, f1: 0.7902743707950788\n",
      "n_estimators: 27, max_depth: 3, learning_rate: 0.3, accuracy: 0.8061395126612517, recall: 0.8621676275087925, precision: 0.7703823919330299, f1: 0.8159204905194386\n",
      "n_estimators: 27, max_depth: 3, learning_rate: 0.4, accuracy: 0.8061634018155756, recall: 0.8635214929416053, precision: 0.7799221509680608, f1: 0.8196477272528364\n",
      "n_estimators: 28, max_depth: 2, learning_rate: 0.1, accuracy: 0.6874343048256092, recall: 0.6931596589859659, precision: 0.6835392112972519, f1: 0.6840032555889358\n",
      "n_estimators: 28, max_depth: 2, learning_rate: 0.2, accuracy: 0.7179049211657907, recall: 0.7393976395921744, precision: 0.7130627188315828, f1: 0.7252118632124287\n",
      "n_estimators: 28, max_depth: 2, learning_rate: 0.3, accuracy: 0.7647276636407071, recall: 0.7917913232158563, precision: 0.7423687451696857, f1: 0.7642563871348924\n",
      "n_estimators: 28, max_depth: 2, learning_rate: 0.4, accuracy: 0.7691352126134735, recall: 0.8111208680419167, precision: 0.747368122480388, f1: 0.770211653716914\n",
      "n_estimators: 28, max_depth: 3, learning_rate: 0.1, accuracy: 0.7549808886765408, recall: 0.7911686948933283, precision: 0.7353299980161683, f1: 0.7606414724935966\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m score_acc \u001b[38;5;241m=\u001b[39m cross_val_score(pipeline, X_train, y_train, cv\u001b[38;5;241m=\u001b[39mkfold, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m score_recall \u001b[38;5;241m=\u001b[39m cross_val_score(pipeline, X_train, y_train, cv\u001b[38;5;241m=\u001b[39mkfold, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m score_precision \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m score_f1 \u001b[38;5;241m=\u001b[39m cross_val_score(pipeline, X_train, y_train, cv\u001b[38;5;241m=\u001b[39mkfold, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_est\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, max_depth: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdepth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, learning_rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore_acc\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore_recall\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore_precision\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, f1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore_f1\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 420\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:525\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    524\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 525\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:603\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    596\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[1;32m    597\u001b[0m             y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    598\u001b[0m             raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    599\u001b[0m             sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    600\u001b[0m         )\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    242\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    244\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 245\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[1;32m    248\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    249\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[1;32m    250\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m    258\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/tree/_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/6.86x/lib/python3.8/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#best parameters :\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "for n_est in range(24, 30, 1):\n",
    "    for depth in range(2, 4, 1):\n",
    "        for lr in [0.1, 0.2, 0.3, 0.4]:\n",
    "            pipeline = Pipeline([\n",
    "                ('outliers_replacer', OutliersReplacer()),\n",
    "                ('drop_columns', DropColumns()),\n",
    "                ('classifier', GradientBoostingClassifier(n_estimators=n_est, max_depth=depth, learning_rate=lr))\n",
    "            ])\n",
    "            kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "            score_acc = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "            score_recall = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='recall')\n",
    "            score_precision = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='precision')\n",
    "            score_f1 = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='f1')\n",
    "            print(f\"n_estimators: {n_est}, max_depth: {depth}, learning_rate: {lr}, accuracy: {score_acc.mean()}, recall: {score_recall.mean()}, precision: {score_precision.mean()}, f1: {score_f1.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8105112279025322, recall: 0.858609212239851, precision: 0.7796499186631607, f1: 0.815952473093291\n"
     ]
    }
   ],
   "source": [
    "#best parameters :\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('outliers_replacer', OutliersReplacer()),\n",
    "        ('drop_columns', DropColumns()),\n",
    "        ('classifier', GradientBoostingClassifier(n_estimators=27, max_depth=3, learning_rate=0.4))\n",
    "    ])\n",
    "\n",
    "\n",
    "#validation \n",
    "kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "score_acc = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "score_recall = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='recall')\n",
    "score_precision = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='precision')\n",
    "score_f1 = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='f1')\n",
    "print(f\"accuracy: {score_acc.mean()}, recall: {score_recall.mean()}, precision: {score_precision.mean()}, f1: {score_f1.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675\n",
      "[[87 27]\n",
      " [25 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       114\n",
      "           1       0.44      0.46      0.45        46\n",
      "\n",
      "    accuracy                           0.68       160\n",
      "   macro avg       0.61      0.61      0.61       160\n",
      "weighted avg       0.68      0.68      0.68       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6.86x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
